{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = 'Hopkins'\n",
    "data_dirs = [\n",
    "        d for d in os.listdir(dataset_path)\n",
    "        if os.path.isdir(os.path.join(dataset_path, d)) and d != \"README.txt\"\n",
    "]\n",
    "\n",
    "num_subspace = {}\n",
    "for data_dir in data_dirs:\n",
    "    mat_file = f\"{data_dir}_truth.mat\"\n",
    "    mat_path = os.path.join(dataset_path, data_dir, mat_file)\n",
    "    mat = scipy.io.loadmat(mat_path)\n",
    "    num_subspace[data_dir] = len(Counter(mat['s'][:,0]))\n",
    "df_meta = pd.DataFrame(num_subspace.items(), columns=['data', 'num_space'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_log(fname):\n",
    "    data = []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                ds_name = line.strip().split(\" - \")[0]\n",
    "                error = float(line.strip().split(\" - \")[1].split(\"Error: \")[1][:-1])\n",
    "                # print(ds_name, error)\n",
    "                data.append([ds_name, error])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    init_error = pd.DataFrame([data[x] for x in range(0, len(data), 2)])\n",
    "    init_error.columns = [\"data\", \"error\"]\n",
    "    init_error[\"data\"] = init_error[\"data\"].astype(str)\n",
    "    model_error = pd.DataFrame([data[x] for x in range(1, len(data), 2)])\n",
    "    model_error.columns = [\"data\", \"error\"]\n",
    "    model_error[\"data\"] = model_error[\"data\"].astype(str)\n",
    "\n",
    "    merged_df = init_error.merge(model_error, on=\"data\",  how='inner',)\n",
    "    merged_df.columns = [\"data\", \"kss\", \"ppca\"]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mppca = read_log(\"logs/mppca_t1_n0.025_paper\")\n",
    "smppca = read_log(\"logs/smppca_test_t1_n0.025_a2.0_paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = mppca.merge(smppca, on=\"data\",  how='inner',)\n",
    "merged_df.columns = [\"data\", \"mppca_kss\", \"mppca\",  \"smppca_kss\", \"smppca\"]\n",
    "merged_df = merged_df.merge(df_meta, on=\"data\",  how='inner',)\n",
    "merged_df.drop(columns=[\"smppca_kss\"], inplace=True)\n",
    "merged_df.rename(columns={\"mppca_kss\": \"kss\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['data', 'kss', 'mppca', 'smppca', 'num_space'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df[merged_df.mppca!=merged_df.smppca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">kss</th>\n",
       "      <th colspan=\"8\" halign=\"left\">mppca</th>\n",
       "      <th colspan=\"8\" halign=\"left\">smppca</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_space</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.0</td>\n",
       "      <td>16.283250</td>\n",
       "      <td>16.663949</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.015</td>\n",
       "      <td>30.3475</td>\n",
       "      <td>49.54</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.251</td>\n",
       "      <td>14.809892</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.945</td>\n",
       "      <td>21.890</td>\n",
       "      <td>49.30</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.61725</td>\n",
       "      <td>15.026648</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.475</td>\n",
       "      <td>22.29</td>\n",
       "      <td>49.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>28.798571</td>\n",
       "      <td>17.241542</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.41</td>\n",
       "      <td>28.850</td>\n",
       "      <td>45.1800</td>\n",
       "      <td>55.04</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.416</td>\n",
       "      <td>16.742252</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.105</td>\n",
       "      <td>20.610</td>\n",
       "      <td>38.775</td>\n",
       "      <td>54.91</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.14800</td>\n",
       "      <td>16.627731</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.24</td>\n",
       "      <td>22.770</td>\n",
       "      <td>39.94</td>\n",
       "      <td>53.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.19</td>\n",
       "      <td>48.19</td>\n",
       "      <td>48.190</td>\n",
       "      <td>48.1900</td>\n",
       "      <td>48.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.15</td>\n",
       "      <td>47.150</td>\n",
       "      <td>47.150</td>\n",
       "      <td>47.150</td>\n",
       "      <td>47.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.15000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.15</td>\n",
       "      <td>47.15</td>\n",
       "      <td>47.150</td>\n",
       "      <td>47.15</td>\n",
       "      <td>47.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             kss                                                              \\\n",
       "           count       mean        std    min    25%     50%      75%    max   \n",
       "num_space                                                                      \n",
       "2          120.0  16.283250  16.663949   0.00   0.00  11.015  30.3475  49.54   \n",
       "3           35.0  28.798571  17.241542   0.00  12.41  28.850  45.1800  55.04   \n",
       "5            1.0  48.190000        NaN  48.19  48.19  48.190  48.1900  48.19   \n",
       "\n",
       "           mppca                                                           \\\n",
       "           count    mean        std    min     25%     50%     75%    max   \n",
       "num_space                                                                   \n",
       "2          120.0  13.251  14.809892   0.00   0.000   8.945  21.890  49.30   \n",
       "3           35.0  25.416  16.742252   0.00  11.105  20.610  38.775  54.91   \n",
       "5            1.0  47.150        NaN  47.15  47.150  47.150  47.150  47.15   \n",
       "\n",
       "          smppca                                                           \n",
       "           count      mean        std    min    25%     50%    75%    max  \n",
       "num_space                                                                  \n",
       "2          120.0  13.61725  15.026648   0.00   0.00   9.475  22.29  49.80  \n",
       "3           35.0  26.14800  16.627731   0.00  11.24  22.770  39.94  53.40  \n",
       "5            1.0  47.15000        NaN  47.15  47.15  47.150  47.15  47.15  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.groupby(\"num_space\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>kss</th>\n",
       "      <th>mppca</th>\n",
       "      <th>smppca</th>\n",
       "      <th>num_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cars6</td>\n",
       "      <td>27.54</td>\n",
       "      <td>10.48</td>\n",
       "      <td>10.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2R3RTC</td>\n",
       "      <td>51.53</td>\n",
       "      <td>49.30</td>\n",
       "      <td>49.86</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1R2RCT_B</td>\n",
       "      <td>25.23</td>\n",
       "      <td>21.85</td>\n",
       "      <td>22.77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cars3_g23</td>\n",
       "      <td>30.43</td>\n",
       "      <td>5.98</td>\n",
       "      <td>5.71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2R3RTC_g12</td>\n",
       "      <td>37.84</td>\n",
       "      <td>37.30</td>\n",
       "      <td>37.84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1RT2RTCRT_B_g12</td>\n",
       "      <td>10.74</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1R2RCT_B_g13</td>\n",
       "      <td>14.04</td>\n",
       "      <td>11.06</td>\n",
       "      <td>11.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>truck2</td>\n",
       "      <td>35.15</td>\n",
       "      <td>15.90</td>\n",
       "      <td>19.67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2T3RCR</td>\n",
       "      <td>55.04</td>\n",
       "      <td>49.87</td>\n",
       "      <td>49.35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>cars2B_g13</td>\n",
       "      <td>48.90</td>\n",
       "      <td>23.76</td>\n",
       "      <td>29.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                data    kss  mppca  smppca  num_space\n",
       "2              cars6  27.54  10.48   10.78          2\n",
       "3             2R3RTC  51.53  49.30   49.86          3\n",
       "11          1R2RCT_B  25.23  21.85   22.77          3\n",
       "12         cars3_g23  30.43   5.98    5.71          2\n",
       "21        2R3RTC_g12  37.84  37.30   37.84          2\n",
       "..               ...    ...    ...     ...        ...\n",
       "148  1RT2RTCRT_B_g12  10.74   9.09    9.92          2\n",
       "149     1R2RCT_B_g13  14.04  11.06   11.49          2\n",
       "150           truck2  35.15  15.90   19.67          2\n",
       "151           2T3RCR  55.04  49.87   49.35          3\n",
       "155       cars2B_g13  48.90  23.76   29.56          2\n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df.mppca!=merged_df.smppca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged_df_2 = merged_df[merged_df.mppca!=merged_df.smppca]\n",
    "\n",
    "df_melted = merged_df_2.melt(id_vars=['data', 'num_space'], value_vars=['kss', 'mppca', 'smppca'],\n",
    "                    var_name='method', value_name='value')\n",
    "\n",
    "df_melted = df_melted[df_melted['num_space']!=5]\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='num_space', y='value', hue='method', data=df_melted)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Comparison of KSS, MPPCA, and S-MPPCA by Subspace')\n",
    "plt.xlabel('Subspace')\n",
    "plt.ylabel('Values')\n",
    "plt.legend(title='Method')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from scipy.linalg import inv, pinv\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools  # for permutations\n",
    "from kss import mppca_init_KSS\n",
    "from data import load_hopkins155\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_assignments(F_hat, mu_hat, Y_test, prop_hat, var_hat, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute the predicted assignments for test data using the trained model.\n",
    "    \"\"\"\n",
    "    d, k = F_hat[0].shape\n",
    "    n = Y_test.shape[1]\n",
    "    J = len(F_hat)\n",
    "\n",
    "    M_inv = []\n",
    "    C_inv = []\n",
    "\n",
    "    for j in range(J):\n",
    "        M_j = var_hat[j] * np.eye(k) + F_hat[j].T @ F_hat[j]\n",
    "        if not np.all(np.isfinite(M_j)):\n",
    "            print(f\"M_j contains NaNs or Infs at component {j+1}, adding regularization.\")\n",
    "            M_j += epsilon * np.eye(k)\n",
    "        try:\n",
    "            M_inv_j = inv(M_j)\n",
    "        except np.linalg.LinAlgError:\n",
    "            M_inv_j = pinv(M_j)\n",
    "        M_inv.append(M_inv_j)\n",
    "\n",
    "        C_inv_j = (1.0 / var_hat[j]) * (np.eye(d) - F_hat[j] @ M_inv_j @ F_hat[j].T)\n",
    "        if not np.all(np.isfinite(C_inv_j)):\n",
    "            print(f\"C_inv_j contains NaNs or Infs at component {j+1}, adding regularization.\")\n",
    "            C_inv_j += epsilon * np.eye(d)\n",
    "        C_inv.append(C_inv_j)\n",
    "\n",
    "    log_likelihood = []\n",
    "    for j in range(J):\n",
    "        # Avoid zero or negative determinants\n",
    "        sign, logdet = np.linalg.slogdet(C_inv[j])\n",
    "        if sign <= 0 or not np.isfinite(logdet):\n",
    "            print(f\"log determinant not positive definite at component {j+1}, using epsilon.\")\n",
    "            logdet = np.log(epsilon)\n",
    "        tmp = -0.5 * np.sum((Y_test - mu_hat[:, [j]]) * (C_inv[j] @ (Y_test - mu_hat[:, [j]])), axis=0)\n",
    "        prop_j = max(prop_hat[j], epsilon)\n",
    "        log_l = np.log(prop_j) + (-d / 2) * np.log(2 * np.pi) + 0.5 * logdet + tmp\n",
    "        log_likelihood.append(log_l)\n",
    "\n",
    "    log_likelihood = np.vstack(log_likelihood)\n",
    "    assgn_hat_indices = np.argmax(log_likelihood, axis=0)\n",
    "    # Map indices back to labels starting from 1\n",
    "    assgn_hat = np.array([j + 1 for j in assgn_hat_indices])\n",
    "    return assgn_hat\n",
    "\n",
    "def get_test_error(Y_test, assgn_test, F0, mu0, prop0, var0, classes):\n",
    "\n",
    "    #  Create mappings between labels and indices\n",
    "    label_to_index = {label: idx for idx, label in enumerate(classes)}\n",
    "    assgn_test_indices = np.array([label_to_index[label] for label in assgn_test])\n",
    "\n",
    "    # Evaluate the KSS initialization on the test data\n",
    "    min_error_init = float('inf')\n",
    "    perms = list(itertools.permutations(range(len(classes))))  # Permutations over component indices\n",
    "    for perm in perms:\n",
    "        # Convert perm to a list or array for indexing\n",
    "        perm_indices = np.array(perm)\n",
    "\n",
    "        # Permute the initial parameters\n",
    "        F_perm = [F0[i] for i in perm_indices]\n",
    "        mu_perm = mu0[:, perm_indices]\n",
    "        var_perm = var0[perm_indices]\n",
    "        prop_perm = prop0[perm_indices]\n",
    "\n",
    "        # Compute predicted assignments using the test data\n",
    "        assgn_pred = test_assignments(F_perm, mu_perm, Y_test, prop_perm, var_perm, epsilon=1e-6)\n",
    "\n",
    "        # Map predicted assignments to indices\n",
    "        assgn_pred_indices = np.array([label_to_index[label] for label in assgn_pred])\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(assgn_test_indices, assgn_pred_indices, labels=range(len(classes)))\n",
    "        row_ind, col_ind = linear_sum_assignment(-cm)\n",
    "        mapping = {col_ind[i]: row_ind[i] for i in range(len(row_ind))}\n",
    "        assgn_pred_mapped = np.array([mapping[idx] for idx in assgn_pred_indices])\n",
    "\n",
    "        # Compute classification error\n",
    "        error = np.mean(assgn_pred_mapped != assgn_test_indices)\n",
    "        if error < min_error_init:\n",
    "            min_error_init = error\n",
    "    return min_error_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['func'] = 'mppca'\n",
    "params['noise'] = 0.025\n",
    "params['temperature'] = 1\n",
    "params['alpha_ent'] = 2\n",
    "params['type_noise'] = 'default'\n",
    "\n",
    "init='KSS'\n",
    "N=156\n",
    "max_iter=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = 'Hopkins'  # Update this path accordingly\n",
    "train_split = 0.8  # Fraction of data to use for training\n",
    "\n",
    "# Load the dataset\n",
    "train_data_list, train_assign_list, dev_assign_list, dev_data_list, test_data_list, test_assign_list, metadata_list = load_hopkins155(dataset_path, \n",
    "                                                                                                                                        train_split=train_split, \n",
    "                                                                                                                                        N=N, \n",
    "                                                                                                                                        noise_value=params['noise'], \n",
    "                                                                                                                                        noise_type=params['type_noise'], \n",
    "                                                                                                                                        data_names=['cars6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:49, 49.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars6 - KSS Init Classification Error: 40.12%\n",
      "cars6 - PCCA Classification Error: 9.58%\n",
      "=== Average Classification Errors Over All Datasets ===\n",
      "KSS Initialization Average Error: 40.12%\n",
      "Average Error: 9.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mppca import homppca_tipping\n",
    "\n",
    "# Initialize accumulators for aggregation\n",
    "total_min_error_init = 0.0  # Accumulator for KSS Initialization errors\n",
    "total_min_error = 0.0       # Accumulator for PCCA errors\n",
    "num_datasets = 0            # Counter for the number of datasets processed\n",
    "\n",
    "# Iterate over each dataset in the Hopkins155 collection\n",
    "for idx, (Y_train, assgn_train, Y_dev, assign_dev, _, _, metadata) in tqdm(enumerate(zip(\n",
    "    train_data_list, train_assign_list, dev_data_list, dev_assign_list, test_data_list, test_assign_list, metadata_list))):\n",
    "\n",
    "    # Normalize data\n",
    "    Y_mean = np.mean(Y_train, axis=1, keepdims=True)\n",
    "    Y_std = np.std(Y_train, axis=1, keepdims=True) + 1e-8\n",
    "    Y_train = (Y_train - Y_mean) / Y_std\n",
    "    Y_dev = (Y_dev - Y_mean) / Y_std\n",
    "\n",
    "    classes = np.unique(assgn_train)  # Labels starting from 1\n",
    "    J = len(classes)\n",
    "    k = 4  # metadata['k']  # Assuming k is set to 4; adjust as needed\n",
    "\n",
    "    # Initialize model\n",
    "    if init == \"KSS\":\n",
    "        F0, _, mu0, prop0, var0 = mppca_init_KSS(Y_train, J, k, max_iter=max_iter)\n",
    "    else:\n",
    "        F0 = [np.random.randn(Y_train.shape[0], k) for _ in range(J)]\n",
    "        mu0 = Y_train[:, np.random.choice(Y_train.shape[1], J, replace=False)]  # Random data points as means\n",
    "        prop0 = np.random.dirichlet(np.ones(J), size=1).flatten()\n",
    "        var0 = np.random.uniform(0.1, 1, size=J)\n",
    "\n",
    "    # get error\n",
    "    min_error_init = get_test_error(Y_dev, assign_dev, F0, mu0, prop0, var0, classes)\n",
    "\n",
    "    # Train the model\n",
    "    F_hat, mu_hat, var_hat, prop_hat = homppca_tipping(Y_train, F0, mu0, prop0, var0, niter=max_iter, epsilon=1e-6,\n",
    "                                                            T=params['temperature'], alpha=params['alpha_ent'], anneal=False)\n",
    "\n",
    "    min_error = get_test_error(Y_dev, assign_dev, F_hat, mu_hat, prop_hat, var_hat, classes)\n",
    "\n",
    "    # Accumulate the errors\n",
    "    total_min_error_init += min_error_init\n",
    "    total_min_error += min_error\n",
    "    num_datasets += 1  # Increment the dataset counter\n",
    "\n",
    "    # Print per-dataset results\n",
    "    print(f\"{metadata['name']} - {init} Init Classification Error: {min_error_init * 100:.2f}%\")\n",
    "    print(f\"{metadata['name']} - PCCA Classification Error: {min_error * 100:.2f}%\")\n",
    "\n",
    "# After processing all datasets, compute and print average errors\n",
    "if num_datasets > 0:\n",
    "    average_min_error_init = total_min_error_init / num_datasets\n",
    "    average_min_error = total_min_error / num_datasets\n",
    "\n",
    "    print(\"=== Average Classification Errors Over All Datasets ===\")\n",
    "    print(f\"{init} Initialization Average Error: {average_min_error_init * 100:.2f}%\")\n",
    "    print(f\"Average Error: {average_min_error * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"No datasets were processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
