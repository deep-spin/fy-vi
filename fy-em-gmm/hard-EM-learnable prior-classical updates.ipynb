{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "013b7508-300c-4c84-8f14-6a6f6df2386f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged over 5 seeds:\n",
      "\n",
      "GMM adjusted MI: 0.6462 ± 0.0159\n",
      "GMM adjusted Rand Index: 0.6312 ± 0.0243\n",
      "GMM Silhouette Score: 0.4217 ± 0.0138\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch.distributions import MultivariateNormal as N\n",
    "\n",
    "# Set manual seeds for reproducibility\n",
    "t.manual_seed(40)\n",
    "np.random.seed(40)\n",
    "\n",
    "# Generate synthetic data once (consistent across seeds)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_FEATURES = 2\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Generate blobs with centers close to each other\n",
    "centers = [[0, 0], [1, 1], [1, -1], [-1, -1]]\n",
    "cluster_std = [0.5, 0.7, 0.9, 0.11]  # Standard deviations\n",
    "\n",
    "X_np, y_np = make_blobs(\n",
    "    n_samples=NUM_SAMPLES,\n",
    "    centers=centers,\n",
    "    cluster_std=cluster_std,\n",
    "    random_state=0\n",
    ")\n",
    "X = t.tensor(X_np, dtype=t.float32)\n",
    "y = t.tensor(y_np, dtype=t.int64)\n",
    "\n",
    "# Add random noise points\n",
    "NUM_NOISE = 100\n",
    "noise = t.rand(NUM_NOISE, NUM_FEATURES) * 6 - 3  # Uniformly between -3 and 3\n",
    "X = t.cat([X, noise], dim=0)\n",
    "y = t.cat([y, t.full((NUM_NOISE,), -1, dtype=t.int64)], dim=0)  # Label noise points as -1\n",
    "\n",
    "# Constants\n",
    "BATCH = X.shape[0]\n",
    "DIM = X.shape[1]\n",
    "GUESS_CLASSES = 4\n",
    "\n",
    "# Define number of seeds\n",
    "num_seeds = 5\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Initialize accumulators for metrics\n",
    "metrics_gmm = {'ami': [], 'ari': [], 'silhouette': []}\n",
    "\n",
    "for seed in seeds:\n",
    "    # Set seed for reproducibility\n",
    "    t.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    ############################\n",
    "    # Gaussian Mixture Model (GMM) with Trainable Prior\n",
    "    ############################\n",
    "    \n",
    "    # Initialize parameters\n",
    "    mu_gmm0 = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    # print(mu_gmm0)\n",
    "    s_gmm0 = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm0 = s_gmm0 @ s_gmm0.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))    \n",
    "    # to replicate the autodiff results that run all the models one after the other \n",
    "\n",
    "    mu_gmm1 = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm1 = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm1 = s_gmm1 @ s_gmm1.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "\n",
    "    mu_gmm = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm = s_gmm @ s_gmm.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "    \n",
    "    # Initialize prior logits\n",
    "    prior_logits = t.zeros(GUESS_CLASSES, requires_grad=False)\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        # E-step\n",
    "        prior = t.distributions.Categorical(logits=prior_logits)\n",
    "        dis = N(mu_gmm, s_gmm)\n",
    "        # log_p_x = dis.log_prob(X[:, None])  # Shape: (BATCH, GUESS_CLASSES)\n",
    "        # z_hard = log_p_x.argmax(-1)\n",
    "        log_p_x_given_z = dis.log_prob(X[:, None])  # Shape: (BATCH, GUESS_CLASSES)\n",
    "        log_pi = t.log(prior.probs)[None, :]  # Shape: (1, GUESS_CLASSES)\n",
    "        log_p_xz = log_p_x_given_z + log_pi  # Shape: (BATCH, GUESS_CLASSES)\n",
    "        z_hard = log_p_xz.argmax(-1)  # Assign each data point to the cluster with highest posterior probability\n",
    "        \n",
    "        # M-step\n",
    "        for k in range(GUESS_CLASSES):\n",
    "            X_k = X[z_hard == k]\n",
    "            if len(X_k) > 0:\n",
    "                mu_gmm[k] = X_k.mean(0)\n",
    "                x_minus_mu = X_k - mu_gmm[k]\n",
    "                s_gmm[k] = (x_minus_mu[:, :, None] @ x_minus_mu[:, None, :]).mean(0)\n",
    "            else:\n",
    "                mu_gmm[k] = t.rand(DIM) * 0.1\n",
    "                s_k = t.rand(DIM, DIM) * 0.1\n",
    "                s_gmm[k] = s_k @ s_k.transpose(-2, -1) + t.eye(DIM)\n",
    "    \n",
    "    # Evaluate Hard EM\n",
    "    labels_gmm = z_hard.numpy()\n",
    "\n",
    "    # Exclude noise points for evaluation\n",
    "    mask = y.numpy() != -1\n",
    "    y_eval = y.numpy()[mask]\n",
    "    labels_gmm_eval = labels_gmm[mask]\n",
    "    X_eval = X.numpy()[mask]\n",
    "    \n",
    "    # GMM Evaluation\n",
    "    metrics_gmm['ami'].append(adjusted_mutual_info_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['ari'].append(adjusted_rand_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['silhouette'].append(silhouette_score(X_eval, labels_gmm_eval))\n",
    "\n",
    "def average_metrics(metrics):\n",
    "    return {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "# Compute standard deviation metrics\n",
    "def std_metrics(metrics):\n",
    "    return {k: np.std(v) for k, v in metrics.items()}\n",
    "\n",
    "avg_gmm = average_metrics(metrics_gmm)\n",
    "std_gmm = std_metrics(metrics_gmm)\n",
    "\n",
    "# Print averaged metrics with standard deviation\n",
    "print('Averaged over 5 seeds:\\n')\n",
    "\n",
    "# GMM Evaluation\n",
    "print('GMM adjusted MI: {:.4f} ± {:.4f}'.format(avg_gmm['ami'], std_gmm['ami']))\n",
    "print('GMM adjusted Rand Index: {:.4f} ± {:.4f}'.format(avg_gmm['ari'], std_gmm['ari']))\n",
    "print('GMM Silhouette Score: {:.4f} ± {:.4f}'.format(avg_gmm['silhouette'], std_gmm['silhouette']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c01836-11ab-4920-8394-ba5686afd8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged over 5 seeds:\n",
      "\n",
      "GMM adjusted MI: 0.5374 ± 0.0877\n",
      "GMM adjusted Rand Index: 0.3480 ± 0.0432\n",
      "GMM Silhouette Score: 0.2074 ± 0.1277\n"
     ]
    }
   ],
   "source": [
    "# learnable prior\n",
    "\n",
    "import numpy as np \n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch.distributions import MultivariateNormal as N\n",
    "\n",
    "# Set manual seeds for reproducibility\n",
    "t.manual_seed(40)\n",
    "np.random.seed(40)\n",
    "\n",
    "# Generate synthetic data once (consistent across seeds)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_FEATURES = 2\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Generate blobs with centers close to each other\n",
    "centers = [[0, 0], [1, 1], [1, -1], [-1, -1]]\n",
    "cluster_std = [0.5, 0.7, 0.9, 0.11]  # Standard deviations\n",
    "\n",
    "X_np, y_np = make_blobs(\n",
    "    n_samples=NUM_SAMPLES,\n",
    "    centers=centers,\n",
    "    cluster_std=cluster_std,\n",
    "    random_state=0\n",
    ")\n",
    "X = t.tensor(X_np, dtype=t.float32)\n",
    "y = t.tensor(y_np, dtype=t.int64)\n",
    "\n",
    "# Add random noise points\n",
    "NUM_NOISE = 100\n",
    "noise = t.rand(NUM_NOISE, NUM_FEATURES) * 6 - 3  # Uniformly between -3 and 3\n",
    "X = t.cat([X, noise], dim=0)\n",
    "y = t.cat([y, t.full((NUM_NOISE,), -1, dtype=t.int64)], dim=0)  # Label noise points as -1\n",
    "\n",
    "# Constants\n",
    "BATCH = X.shape[0]\n",
    "DIM = X.shape[1]\n",
    "GUESS_CLASSES = 4\n",
    "\n",
    "# Define number of seeds\n",
    "num_seeds = 5\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Initialize accumulators for metrics\n",
    "metrics_gmm = {'ami': [], 'ari': [], 'silhouette': []}\n",
    "\n",
    "for seed in seeds:\n",
    "    # Set seed for reproducibility\n",
    "    t.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    ############################\n",
    "    # Gaussian Mixture Model (GMM) with Trainable Prior\n",
    "    ############################\n",
    "    \n",
    "    # Initialize parameters\n",
    "    mu_gmm0 = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    # print(mu_gmm0)\n",
    "    s_gmm0 = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm0 = s_gmm0 @ s_gmm0.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))    \n",
    "    # to replicate the autodiff results that run all the models one after the other \n",
    "\n",
    "    mu_gmm1 = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm1 = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm1 = s_gmm1 @ s_gmm1.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "\n",
    "    mu_gmm = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm = s_gmm @ s_gmm.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "    \n",
    "    # Initialize prior logits\n",
    "    prior_logits = t.zeros(GUESS_CLASSES, requires_grad=False)\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        # E-step\n",
    "        prior = t.distributions.Categorical(logits=prior_logits)\n",
    "        dis = N(mu_gmm, s_gmm)\n",
    "        # log_p_x = dis.log_prob(X[:, None])  # Shape: (BATCH, GUESS_CLASSES)\n",
    "        # z_hard = log_p_x.argmax(-1)\n",
    "        log_p_x_given_z = dis.log_prob(X[:, None])  # Shape: (BATCH, GUESS_CLASSES)\n",
    "        log_pi = t.log(prior.probs)[None, :]  # Shape: (1, GUESS_CLASSES)\n",
    "        log_p_xz = log_p_x_given_z + log_pi  # Shape: (BATCH, GUESS_CLASSES)\n",
    "        z_hard = log_p_xz.argmax(-1)  # Assign each data point to the cluster with highest posterior probability\n",
    "        \n",
    "        # M-step\n",
    "        for k in range(GUESS_CLASSES):\n",
    "            X_k = X[z_hard == k]\n",
    "            if len(X_k) > 0:\n",
    "                mu_gmm[k] = X_k.mean(0)\n",
    "                x_minus_mu = X_k - mu_gmm[k]\n",
    "                s_gmm[k] = (x_minus_mu[:, :, None] @ x_minus_mu[:, None, :]).mean(0)\n",
    "            else:\n",
    "                mu_gmm[k] = t.rand(DIM) * 0.1\n",
    "                s_k = t.rand(DIM, DIM) * 0.1\n",
    "                s_gmm[k] = s_k @ s_k.transpose(-2, -1) + t.eye(DIM)\n",
    "\n",
    "        N_k = t.bincount(z_hard)#z_hard.sum(dim=0)\n",
    "        # print(N_k)\n",
    "        prior_logits = N_k.log()\n",
    "        \n",
    "    # Evaluate Hard EM\n",
    "    labels_gmm = z_hard.numpy()\n",
    "\n",
    "    # Exclude noise points for evaluation\n",
    "    mask = y.numpy() != -1\n",
    "    y_eval = y.numpy()[mask]\n",
    "    labels_gmm_eval = labels_gmm[mask]\n",
    "    X_eval = X.numpy()[mask]\n",
    "    \n",
    "    # GMM Evaluation\n",
    "    metrics_gmm['ami'].append(adjusted_mutual_info_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['ari'].append(adjusted_rand_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['silhouette'].append(silhouette_score(X_eval, labels_gmm_eval))\n",
    "\n",
    "def average_metrics(metrics):\n",
    "    return {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "# Compute standard deviation metrics\n",
    "def std_metrics(metrics):\n",
    "    return {k: np.std(v) for k, v in metrics.items()}\n",
    "\n",
    "avg_gmm = average_metrics(metrics_gmm)\n",
    "std_gmm = std_metrics(metrics_gmm)\n",
    "\n",
    "# Print averaged metrics with standard deviation\n",
    "print('Averaged over 5 seeds:\\n')\n",
    "\n",
    "# GMM Evaluation\n",
    "print('GMM adjusted MI: {:.4f} ± {:.4f}'.format(avg_gmm['ami'], std_gmm['ami']))\n",
    "print('GMM adjusted Rand Index: {:.4f} ± {:.4f}'.format(avg_gmm['ari'], std_gmm['ari']))\n",
    "print('GMM Silhouette Score: {:.4f} ± {:.4f}'.format(avg_gmm['silhouette'], std_gmm['silhouette']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f84847-a2b0-43df-b411-186336c75974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
