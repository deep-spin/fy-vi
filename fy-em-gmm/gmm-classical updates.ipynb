{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94e91816-451f-47e6-8e16-0b1e7bfdb2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged over 5 seeds:\n",
      "\n",
      "GMM adjusted MI: 0.5439 ± 0.0040\n",
      "GMM adjusted Rand Index: 0.4854 ± 0.0043\n",
      "GMM Silhouette Score: 0.3301 ± 0.0073\n"
     ]
    }
   ],
   "source": [
    "# fixed prior softmax update\n",
    "\n",
    "import numpy as np \n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch.distributions import MultivariateNormal as N\n",
    "\n",
    "# Set manual seeds for reproducibility\n",
    "t.manual_seed(40)\n",
    "np.random.seed(40)\n",
    "\n",
    "# Generate synthetic data once (consistent across seeds)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_FEATURES = 2\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Generate blobs with centers close to each other\n",
    "centers = [[0, 0], [1, 1], [1, -1], [-1, -1]]\n",
    "cluster_std = [0.5, 0.7, 0.9, 0.11]  # Standard deviations\n",
    "\n",
    "X_np, y_np = make_blobs(\n",
    "    n_samples=NUM_SAMPLES,\n",
    "    centers=centers,\n",
    "    cluster_std=cluster_std,\n",
    "    random_state=0\n",
    ")\n",
    "X = t.tensor(X_np, dtype=t.float32)\n",
    "y = t.tensor(y_np, dtype=t.int64)\n",
    "\n",
    "# Add random noise points\n",
    "NUM_NOISE = 100\n",
    "noise = t.rand(NUM_NOISE, NUM_FEATURES) * 6 - 3  # Uniformly between -3 and 3\n",
    "X = t.cat([X, noise], dim=0)\n",
    "y = t.cat([y, t.full((NUM_NOISE,), -1, dtype=t.int64)], dim=0)  # Label noise points as -1\n",
    "\n",
    "# Constants\n",
    "BATCH = X.shape[0]\n",
    "DIM = X.shape[1]\n",
    "GUESS_CLASSES = 4\n",
    "\n",
    "# Define number of seeds\n",
    "num_seeds = 5\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Initialize accumulators for metrics\n",
    "metrics_gmm = {'ami': [], 'ari': [], 'silhouette': []}\n",
    "\n",
    "for seed in seeds:\n",
    "    # Set seed for reproducibility\n",
    "    t.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    #################################\n",
    "    # Gaussian Mixture Model (GMM) #\n",
    "    ################################\n",
    "    \n",
    "    # Initialize parameters\n",
    "    mu_gmm = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm = s_gmm @ s_gmm.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        # E-step\n",
    "        prior = t.distributions.Categorical(logits=t.zeros(GUESS_CLASSES))\n",
    "        dis = N(mu_gmm, s_gmm)\n",
    "        \n",
    "        log_p_x_given_z = dis.log_prob(X[:, None])  # Shape (BATCH, GUESS_CLASSES)\n",
    "        log_p_z = prior.probs.log()[None, :]  # Shape (1, GUESS_CLASSES)\n",
    "        log_p_xz = log_p_x_given_z + log_p_z  # Shape (BATCH, GUESS_CLASSES)\n",
    "        \n",
    "        # Compute q_gmm (posterior probabilities)\n",
    "        q_gmm = t.softmax(log_p_xz, dim=1)  # Shape (BATCH, GUESS_CLASSES)\n",
    "        \n",
    "        # M-step\n",
    "        mu_gmm = (q_gmm[:, :, None] * X[:, None, :]).sum(0) / q_gmm.sum(0)[:, None]\n",
    "        x_minus_mu = X[:, None, :] - mu_gmm[None, :, :]\n",
    "        s_gmm = ((x_minus_mu[:, :, :, None] @ x_minus_mu[:, :, None, :]) * q_gmm[:, :, None, None]).sum(0) / q_gmm.sum(0)[:, None, None]\n",
    "    \n",
    "    # Evaluate GMM\n",
    "    labels_gmm = q_gmm.argmax(1).numpy()\n",
    "\n",
    "    # Exclude noise points for evaluation\n",
    "    mask = y.numpy() != -1\n",
    "    y_eval = y.numpy()[mask]\n",
    "    labels_gmm_eval = labels_gmm[mask]\n",
    "    X_eval = X.numpy()[mask]\n",
    "    \n",
    "    # GMM Evaluation\n",
    "    metrics_gmm['ami'].append(adjusted_mutual_info_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['ari'].append(adjusted_rand_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['silhouette'].append(silhouette_score(X_eval, labels_gmm_eval))\n",
    "\n",
    "def average_metrics(metrics):\n",
    "    return {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "# Compute standard deviation metrics\n",
    "def std_metrics(metrics):\n",
    "    return {k: np.std(v) for k, v in metrics.items()}\n",
    "\n",
    "avg_gmm = average_metrics(metrics_gmm)\n",
    "std_gmm = std_metrics(metrics_gmm)\n",
    "\n",
    "# Print averaged metrics with standard deviation\n",
    "print('Averaged over 5 seeds:\\n')\n",
    "\n",
    "# GMM Evaluation\n",
    "print('GMM adjusted MI: {:.4f} ± {:.4f}'.format(avg_gmm['ami'], std_gmm['ami']))\n",
    "print('GMM adjusted Rand Index: {:.4f} ± {:.4f}'.format(avg_gmm['ari'], std_gmm['ari']))\n",
    "print('GMM Silhouette Score: {:.4f} ± {:.4f}'.format(avg_gmm['silhouette'], std_gmm['silhouette']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a54cc59c-3602-4152-9788-0bfc985a2680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged over 5 seeds:\n",
      "\n",
      "GMM adjusted MI: 0.6056 ± 0.0123\n",
      "GMM adjusted Rand Index: 0.5305 ± 0.0049\n",
      "GMM Silhouette Score: 0.3454 ± 0.0319\n"
     ]
    }
   ],
   "source": [
    "# learnable prior, totally classical update\n",
    "\n",
    "import numpy as np \n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch.distributions import MultivariateNormal as N\n",
    "\n",
    "# Set manual seeds for reproducibility\n",
    "t.manual_seed(40)\n",
    "np.random.seed(40)\n",
    "\n",
    "# Generate synthetic data once (consistent across seeds)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_FEATURES = 2\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Generate blobs with centers close to each other\n",
    "centers = [[0, 0], [1, 1], [1, -1], [-1, -1]]\n",
    "cluster_std = [0.5, 0.7, 0.9, 0.11]  # Standard deviations\n",
    "\n",
    "X_np, y_np = make_blobs(\n",
    "    n_samples=NUM_SAMPLES,\n",
    "    centers=centers,\n",
    "    cluster_std=cluster_std,\n",
    "    random_state=0\n",
    ")\n",
    "X = t.tensor(X_np, dtype=t.float32)\n",
    "y = t.tensor(y_np, dtype=t.int64)\n",
    "\n",
    "# Add random noise points\n",
    "NUM_NOISE = 100\n",
    "noise = t.rand(NUM_NOISE, NUM_FEATURES) * 6 - 3  # Uniformly between -3 and 3\n",
    "X = t.cat([X, noise], dim=0)\n",
    "y = t.cat([y, t.full((NUM_NOISE,), -1, dtype=t.int64)], dim=0)  # Label noise points as -1\n",
    "\n",
    "# Constants\n",
    "BATCH = X.shape[0]\n",
    "DIM = X.shape[1]\n",
    "GUESS_CLASSES = 4\n",
    "\n",
    "# Define number of seeds\n",
    "num_seeds = 5\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Initialize accumulators for metrics\n",
    "metrics_gmm = {'ami': [], 'ari': [], 'silhouette': []}\n",
    "\n",
    "for seed in seeds:\n",
    "    # Set seed for reproducibility\n",
    "    t.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    ############################\n",
    "    # Gaussian Mixture Model (GMM) with Standard EM Updates\n",
    "    ############################\n",
    "    \n",
    "    # Initialize parameters\n",
    "    mu_gmm = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm = s_gmm @ s_gmm.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "    pi_k = t.ones(GUESS_CLASSES) / GUESS_CLASSES  # Initialize mixing coefficients\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        # E-step\n",
    "        dis = N(mu_gmm, s_gmm)\n",
    "        log_p_x_given_z = dis.log_prob(X[:, None])  # Shape (BATCH, GUESS_CLASSES)\n",
    "        p_x_given_z = log_p_x_given_z.exp()\n",
    "        p_z = pi_k[None, :]  # Shape (1, GUESS_CLASSES)\n",
    "        p_xz = p_x_given_z * p_z  # Shape (BATCH, GUESS_CLASSES)\n",
    "        gamma_nk = p_xz / p_xz.sum(dim=1, keepdim=True)  # Shape (BATCH, GUESS_CLASSES)\n",
    "        \n",
    "        # M-step\n",
    "        N_k = gamma_nk.sum(dim=0)  # Shape (GUESS_CLASSES,)\n",
    "        pi_k = N_k / BATCH  # Update mixing coefficients\n",
    "        \n",
    "        mu_gmm = (gamma_nk[:, :, None] * X[:, None, :]).sum(0) / N_k[:, None]\n",
    "        x_minus_mu = X[:, None, :] - mu_gmm[None, :, :]\n",
    "        s_gmm = ((gamma_nk[:, :, None, None] * (x_minus_mu[:, :, :, None] * x_minus_mu[:, :, None, :])).sum(0)) / N_k[:, None, None]\n",
    "        \n",
    "        # Add a small value to the diagonal to prevent singularity\n",
    "        s_gmm += t.eye(DIM)[None, :, :] * 1e-6\n",
    "    \n",
    "    # Evaluate GMM\n",
    "    labels_gmm = gamma_nk.argmax(1).numpy()\n",
    "\n",
    "    # Exclude noise points for evaluation\n",
    "    mask = y.numpy() != -1\n",
    "    y_eval = y.numpy()[mask]\n",
    "    labels_gmm_eval = labels_gmm[mask]\n",
    "    X_eval = X.numpy()[mask]\n",
    "    \n",
    "    # GMM Evaluation\n",
    "    metrics_gmm['ami'].append(adjusted_mutual_info_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['ari'].append(adjusted_rand_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['silhouette'].append(silhouette_score(X_eval, labels_gmm_eval))\n",
    "\n",
    "def average_metrics(metrics):\n",
    "    return {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "# Compute standard deviation metrics\n",
    "def std_metrics(metrics):\n",
    "    return {k: np.std(v) for k, v in metrics.items()}\n",
    "\n",
    "avg_gmm = average_metrics(metrics_gmm)\n",
    "std_gmm = std_metrics(metrics_gmm)\n",
    "\n",
    "# Print averaged metrics with standard deviation\n",
    "print('Averaged over 5 seeds:\\n')\n",
    "\n",
    "# GMM Evaluation\n",
    "print('GMM adjusted MI: {:.4f} ± {:.4f}'.format(avg_gmm['ami'], std_gmm['ami']))\n",
    "print('GMM adjusted Rand Index: {:.4f} ± {:.4f}'.format(avg_gmm['ari'], std_gmm['ari']))\n",
    "print('GMM Silhouette Score: {:.4f} ± {:.4f}'.format(avg_gmm['silhouette'], std_gmm['silhouette']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4c9aa7-9a71-46b5-b0fa-8f98727ccc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged over 5 seeds:\n",
      "\n",
      "GMM adjusted MI: 0.6056 ± 0.0123\n",
      "GMM adjusted Rand Index: 0.5305 ± 0.0049\n",
      "GMM Silhouette Score: 0.3454 ± 0.0319\n"
     ]
    }
   ],
   "source": [
    "# learnable prior, softmax update\n",
    "\n",
    "import numpy as np \n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from torch.distributions import MultivariateNormal as N\n",
    "\n",
    "# Set manual seeds for reproducibility\n",
    "t.manual_seed(40)\n",
    "np.random.seed(40)\n",
    "\n",
    "# Generate synthetic data once (consistent across seeds)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_FEATURES = 2\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Generate blobs with centers close to each other\n",
    "centers = [[0, 0], [1, 1], [1, -1], [-1, -1]]\n",
    "cluster_std = [0.5, 0.7, 0.9, 0.11]  # Standard deviations\n",
    "\n",
    "X_np, y_np = make_blobs(\n",
    "    n_samples=NUM_SAMPLES,\n",
    "    centers=centers,\n",
    "    cluster_std=cluster_std,\n",
    "    random_state=0\n",
    ")\n",
    "X = t.tensor(X_np, dtype=t.float32)\n",
    "y = t.tensor(y_np, dtype=t.int64)\n",
    "\n",
    "# Add random noise points\n",
    "NUM_NOISE = 100\n",
    "noise = t.rand(NUM_NOISE, NUM_FEATURES) * 6 - 3  # Uniformly between -3 and 3\n",
    "X = t.cat([X, noise], dim=0)\n",
    "y = t.cat([y, t.full((NUM_NOISE,), -1, dtype=t.int64)], dim=0)  # Label noise points as -1\n",
    "\n",
    "# Constants\n",
    "BATCH = X.shape[0]\n",
    "DIM = X.shape[1]\n",
    "GUESS_CLASSES = 4\n",
    "\n",
    "# Define number of seeds\n",
    "num_seeds = 5\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Initialize accumulators for metrics\n",
    "metrics_gmm = {'ami': [], 'ari': [], 'silhouette': []}\n",
    "\n",
    "for seed in seeds:\n",
    "    # Set seed for reproducibility\n",
    "    t.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    ############################\n",
    "    # Gaussian Mixture Model (GMM) with Trainable Prior\n",
    "    ############################\n",
    "    \n",
    "    # Initialize parameters\n",
    "    mu_gmm = t.rand(GUESS_CLASSES, DIM) * 0.1\n",
    "    s_gmm = t.rand(GUESS_CLASSES, DIM, DIM) * 0.1\n",
    "    s_gmm = s_gmm @ s_gmm.transpose(-2, -1) + t.einsum('ij,k->kij', t.eye(DIM), t.ones(GUESS_CLASSES))\n",
    "    \n",
    "    # Initialize prior logits\n",
    "    prior_logits = t.zeros(GUESS_CLASSES, requires_grad=False)\n",
    "    \n",
    "    for epoch in range(200):\n",
    "        # E-step\n",
    "        dis = N(mu_gmm, s_gmm)\n",
    "        log_p_x_given_z = dis.log_prob(X[:, None])  # Shape (BATCH, GUESS_CLASSES)\n",
    "        log_p_z = t.log_softmax(prior_logits, dim=0)[None, :]  # Shape (1, GUESS_CLASSES)\n",
    "        log_p_xz = log_p_x_given_z + log_p_z  # Shape (BATCH, GUESS_CLASSES)\n",
    "        \n",
    "        # Compute q_gmm (posterior probabilities)\n",
    "        # log_q_gmm = log_p_xz - t.logsumexp(log_p_xz, dim=1, keepdim=True)\n",
    "        # q_gmm = log_q_gmm.exp()  # Shape (BATCH, GUESS_CLASSES)\n",
    "\n",
    "        q_gmm = t.softmax(log_p_xz, dim=1)  # Shape (BATCH, GUESS_CLASSES)\n",
    "        \n",
    "        # M-step\n",
    "        N_k = q_gmm.sum(dim=0)  # Effective number of data points assigned to each cluster\n",
    "        \n",
    "        # Update prior logits directly based on N_k\n",
    "        prior_logits = N_k.log()\n",
    "        \n",
    "        # Update means\n",
    "        mu_gmm = (q_gmm[:, :, None] * X[:, None, :]).sum(0) / N_k[:, None]\n",
    "        \n",
    "        # Update covariances\n",
    "        x_minus_mu = X[:, None, :] - mu_gmm[None, :, :]\n",
    "        s_gmm = ((q_gmm[:, :, None, None] * (x_minus_mu[:, :, :, None] * x_minus_mu[:, :, None, :])).sum(0)) / N_k[:, None, None]\n",
    "        \n",
    "        # Avoid singular covariance matrices\n",
    "        s_gmm += t.eye(DIM)[None, :, :] * 1e-6\n",
    "    \n",
    "    # Evaluate GMM\n",
    "    labels_gmm = q_gmm.argmax(1).numpy()\n",
    "\n",
    "    # Exclude noise points for evaluation\n",
    "    mask = y.numpy() != -1\n",
    "    y_eval = y.numpy()[mask]\n",
    "    labels_gmm_eval = labels_gmm[mask]\n",
    "    X_eval = X.numpy()[mask]\n",
    "    \n",
    "    # GMM Evaluation\n",
    "    metrics_gmm['ami'].append(adjusted_mutual_info_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['ari'].append(adjusted_rand_score(labels_gmm_eval, y_eval))\n",
    "    metrics_gmm['silhouette'].append(silhouette_score(X_eval, labels_gmm_eval))\n",
    "\n",
    "def average_metrics(metrics):\n",
    "    return {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "# Compute standard deviation metrics\n",
    "def std_metrics(metrics):\n",
    "    return {k: np.std(v) for k, v in metrics.items()}\n",
    "\n",
    "avg_gmm = average_metrics(metrics_gmm)\n",
    "std_gmm = std_metrics(metrics_gmm)\n",
    "\n",
    "# Print averaged metrics with standard deviation\n",
    "print('Averaged over 5 seeds:\\n')\n",
    "\n",
    "# GMM Evaluation\n",
    "print('GMM adjusted MI: {:.4f} ± {:.4f}'.format(avg_gmm['ami'], std_gmm['ami']))\n",
    "print('GMM adjusted Rand Index: {:.4f} ± {:.4f}'.format(avg_gmm['ari'], std_gmm['ari']))\n",
    "print('GMM Silhouette Score: {:.4f} ± {:.4f}'.format(avg_gmm['silhouette'], std_gmm['silhouette']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35fbc1-94dc-4a1a-a31b-23fd01d7651e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
